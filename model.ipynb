{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22ngLgyuAOw",
        "outputId": "e2f2a9ed-ed4c-465d-e386-b9faadf4dfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1428 images belonging to 2 classes.\n",
            "Found 357 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 358s 8s/step - loss: 0.1720 - accuracy: 0.9356 - val_loss: 0.0527 - val_accuracy: 0.9804\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 331s 7s/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0228 - val_accuracy: 0.9888\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 314s 7s/step - loss: 0.0177 - accuracy: 0.9930 - val_loss: 0.0189 - val_accuracy: 0.9944\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 315s 7s/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 313s 7s/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 315s 7s/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 309s 7s/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9972\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 313s 7s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 315s 7s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 315s 7s/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.0016 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 515 images belonging to 2 classes.\n",
            "17/17 [==============================] - 71s 4s/step - loss: 0.1311 - accuracy: 0.9709\n",
            "Test Accuracy: 0.9709, Test Loss: 0.1311\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the path to your dataset containing fire and non-fire images\n",
        "train_data_dir = 'train'\n",
        "test_data_dir = 'test'\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for training and testing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Create a pre-trained MobileNetV2 model as the base\n",
        "base_model = MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(img_width, img_height, 3)\n",
        ")\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "# Save the model for future use\n",
        "model.save('fire_detection_model.h5')\n",
        "\n",
        "# Optional: Create a test generator and evaluate the model\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sU3O_sWAlSc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "tWF5O4rD68bJ",
        "outputId": "5756c3a9-c57a-4b84-e7e4-5d4dcf5d6d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d6486d659331>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mAlarm_Status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Value in ret is True # To read video frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# To convert frame into gray color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mfire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfire_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Haar Cascade Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ],
      "source": [
        "import cv2         # Library for openCV\n",
        "import threading   # Library for threading -- which allows code to run in backend\n",
        "import pygame   # Library for alarm sound\n",
        "import smtplib     # Library for email sending\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from email.message import EmailMessage\n",
        "import ssl\n",
        "\n",
        "fire_cascade = cv2.CascadeClassifier('fire_detection_cascade_model.xml') # To access xml file which includes positive and negative images of fire. (Trained images)\n",
        "\n",
        "vid = cv2.VideoCapture(0) # To start camera this command is used \"0\" for laptop inbuilt camera and \"1\" for USB attahed camera for pc\n",
        "runOnce = False # created boolean\n",
        "\n",
        "# define rez\n",
        "resTrack = (640,480) #or whatever\n",
        "resWrite = (1280, 720)\n",
        "vid.set( cv2.CAP_PROP_FRAME_WIDTH, resWrite[0])\n",
        "vid.set( cv2.CAP_PROP_FRAME_HEIGHT, resWrite[1])\n",
        "\n",
        "def play_alarm_sound_function():\n",
        "    pygame.init()  # Initialize the video system (even though we're working with audio)\n",
        "    pygame.mixer.init()\n",
        "    pygame.mixer.music.load('Alarm Sound.mp3')\n",
        "    pygame.mixer.music.play()\n",
        "    pygame.event.wait()\n",
        "\n",
        "\n",
        "# def send_mail_function(): # defined function to send mail post fire detection using threading\n",
        "\n",
        "#     email_sender = 'qwicklab321@gmail.com'\n",
        "#     email_password = 'Qwicklab@123'\n",
        "#     email_reciver = 'bhaveshpatil3214@gmail.com'\n",
        "\n",
        "#     subject = 'Fire is detected'\n",
        "#     body = '\"Warning: Fire accident has been detected. Please take necessary actions.\"'\n",
        "\n",
        "\n",
        "#     em = EmailMessage()\n",
        "\n",
        "#     em['from'] = email_sender\n",
        "#     em['to'] = email_reciver\n",
        "#     em['subject'] = subject\n",
        "#     em.set_content(body)\n",
        "\n",
        "#     content = ssl.create_default_context()\n",
        "\n",
        "#     with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=content) as smtp:\n",
        "#         smtp.login(email_sender, email_password)\n",
        "#         smtp.sendmail(email_sender, email_reciver, em.as_string())\n",
        "\n",
        "\n",
        "# def internet_on():\n",
        "#     try:\n",
        "#         response = urllib.request.urlopen('https://www.google.co.in', timeout=1)\n",
        "#         return True\n",
        "#     except urllib.error.URLError as err:\n",
        "#         pass\n",
        "#     return False\n",
        "\n",
        "\n",
        "while(True):\n",
        "    Alarm_Status = False\n",
        "    ret, frame = vid.read() # Value in ret is True # To read video frame\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # To convert frame into gray color\n",
        "    fire = fire_cascade.detectMultiScale(frame, 1.2, 5) # Haar Cascade Classifier\n",
        "\n",
        "    ## to highlight fire with square\n",
        "    # Inside the loop where fire is detected\n",
        "    for (x, y, w, h) in fire:\n",
        "        cv2.rectangle(frame, (x - 20, y - 20), (x + w + 20, y + h + 20), (0, 0, 255), 2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = frame[y:y+h, x:x+w]\n",
        "\n",
        "        # Calculate confidence based on average pixel intensity\n",
        "        confidence = roi_gray.mean()\n",
        "\n",
        "        cv2.putText(frame, f'Fire: {confidence:.2f}', (x - 20, y - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        print(\"Fire alarm initiated\")\n",
        "        threading.Thread(target=play_alarm_sound_function).start()  # To call alarm thread\n",
        "\n",
        "        # if runOnce == False:\n",
        "        #     print(\"Mail send initiated\")\n",
        "        #     threading.Thread(target=send_mail_function).start()  # To call alarm thread\n",
        "        #     runOnce = True\n",
        "\n",
        "        # if runOnce == True:\n",
        "        #     print(\"Mail is already sent once\")\n",
        "        #     print(internet_on())\n",
        "        #     runOnce = True\n",
        "\n",
        "    cv2.imshow('Fire Detection System', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "vid.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
